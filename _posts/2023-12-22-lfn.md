---
layout: post
title: Light Field Networks
subtitle: 6.S980 Final Project
thumbnail-img: /assets/img/chair.png
mathjax: true
---

This was my team's final project for 6.S980, Machine Learning for Inverse Graphics, where we recreated a light field network (LFN).

## Introduction

We create a "toy" version of the light field network proposed in ”Light Field Networks: Neural Scene Representations with
Single-Evaluation Rendering” by Sitzmann et al. (my professor for this class!). Additionally, we add multi-view consistency to allow for novel scene generation with learned latent codes.

## Methodology

We first overfit on a single scene, where we are able to reconstruct training views of a single chair.

This itself doesn't have novel view generation, as light fields do not have built-in multi-view consistency. To achieve this, we implement an autodecoder to learn the latent sppace and latent codes for different scenes.

## Experimentation

Overfitting on a single scene:

![overfit](/assets/img/chair_overfit.png){: .mx-auto.d-block :}

## Final Output

Novel view generation:

![overfit](/assets/img/novel_view_chair.png){: .mx-auto.d-block :}

## Final Thoughts

It could look better with more thorough training and implementation, but we were able to implement a fundamentally correct LFN.
